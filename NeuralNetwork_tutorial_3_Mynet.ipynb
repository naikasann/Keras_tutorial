{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork_tutorial_3_Mynet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOimubdzb1wZHy8+dyh4HtI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naikasann/Keras_tutorial/blob/master/NeuralNetwork_tutorial_3_Mynet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdGp4EdYQBBk",
        "colab_type": "text"
      },
      "source": [
        "# Kerasを触ってみる(第3章 自分のデータセットを学習してみる)\n",
        "\n",
        "次は自分でデータセットを作成してそれを学習してみましょう。\n",
        "今回は動画を２パターン(○○がある、○○がない)を撮影して毎フレームを画像にして学習し、画像に○○があるのかないのか判別するニューラルネットワークを作成してみましょう。\n",
        "\n",
        "---\n",
        "\n",
        "# 動画から画像を取り出してみる\n",
        "\n",
        "まずは動画から画像を取り出してみましょう。\n",
        "\n",
        "---\n",
        "\n",
        "## 動画を画像に変換する。\n",
        "\n",
        "動画から全フレームを画像に保存する関数を作成し、その後動画をアップロードその関数を実行して画像を作成しましょう。まずは動画をフレーム毎に区切り画像にするメソッドを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO5PqcMWJOHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 動画を画像にする関数の定義\n",
        "\n",
        "# ライブラリのインポート\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def save_all_frames(video_path, dir_path, savename, ext=\"jpg\"):\n",
        "    # 動画を読み取る\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # 読めこめなかった場合\n",
        "    if not cap.isOpened():\n",
        "        print(\"cant open.\")\n",
        "        return None\n",
        "    # フォルダーの作成\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    base_path = os.path.join(dir_path, savename)\n",
        "\n",
        "    # フレームを取り出す\n",
        "    frames = len(str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))\n",
        "    n = 0\n",
        "\n",
        "    while True:\n",
        "        # フレームから情報を取得する\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            # 画像を生成。保存する(その時にリサイズもかけておく)\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            cv2.imwrite('{}_{}.{}'.format(base_path, str(n).zfill(frames), ext), frame)\n",
        "            n += 1\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufpz7uI33v4X",
        "colab_type": "text"
      },
      "source": [
        "このようなメソッドで動画を画像にすることができます。\n",
        "ただこのやり方だと区切りが早すぎて同じような画像が多く出現するため、実際に動画から抽出する場合はもう少し工夫をした方がいい結果になります。\n",
        "\n",
        "---\n",
        "## 動画をアップロードしてみよう\n",
        "\n",
        "次に動画をアップデートしましょう。またアップロードされた動画から画像に切り出すメソッドも実行しましょう。\n",
        "たくさんの画像が生成されることがわかると思います。\n",
        "\n",
        "まずはmp4が対応しているのでmp4の動画をアップロードしてみましょう。\n",
        "ここはgoogle colabの機能などを利用しているだけなのであまり覚えなくていいです。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HysYC2omMaya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ２つの動画のアップロード\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"１つ目の動画を選択してください\")\n",
        "uploaded = files.upload()\n",
        "print(\"2つ目の動画を選択してください\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\"meke directory dataset...\")\n",
        "!mkdir dataset\n",
        "print(\"category1 folder make...\")\n",
        "!mkdir ./dataset/category1\n",
        "print(\"category2 folder make...\")\n",
        "!mkdir ./dataset/category2\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izJWm_CNP5Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 動画から画像を生成する\n",
        "\n",
        "# 動画のファイル名を書く。\n",
        "moviename1 = \"./midori.mp4\"\n",
        "moviename2 = \"./murasaki.mp4\"\n",
        "# Name of the folder to save.\n",
        "savefolder1 = './dataset/category1/'\n",
        "savefolder2 = './dataset/category2/'\n",
        "# File name to save\n",
        "savefile1 = \"cat1\"\n",
        "savefile2 = \"cat2\"\n",
        "\n",
        "# 動画を画像にする。\n",
        "save_all_frames(moviename1, savefolder1, savefile1)\n",
        "save_all_frames(moviename2, savefolder2, savefile2)\n",
        "\n",
        "# 画像ができているのか確認する\n",
        "print(\"category 1 の画像リスト\")\n",
        "!ls ./dataset/category1\n",
        "print(\"category 2 の画像リスト\")\n",
        "!ls ./dataset/category2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddXNOaxKV5gn",
        "colab_type": "text"
      },
      "source": [
        "これで画像の生成は完了です。\n",
        "現在の構成は\n",
        "\n",
        "```\n",
        "[root(current directory)]---[dataset] --- [category1(folder)] ---  [image_file1(.jpg)]\n",
        "                                       |                       |--- [image_file2(.jpg)]\n",
        "                                       |                             ...\n",
        "                                       |-- [category2(folder)] ---  [image_file1(.jpg)]\n",
        "                                                              |--  [image_file2(.jpg)]\n",
        "                                                                    ...\n",
        "```\n",
        "このような構成になります。\n",
        "まずは取り込んだ画像を表示してみましょう。\n",
        "\n",
        "---\n",
        "\n",
        "## ライブラリをインポートする\n",
        "\n",
        "まずはライブラリをインポートします。\n",
        "個々の説明は省略。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZx5f307Xbis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリを読み取れる\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D,Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex8Pxo1E6sPO",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## 自作データセットを作成する\n",
        "\n",
        "次は自作したデータセットを読み込んでみましょう。\n",
        "画像を読み込んで処理するときにはファイルのパスから画像を呼び出し、その画像を格納しておくリストと、その画像の分類を示したリストの二つを生成する必要があります。\n",
        "\n",
        "Kerasにはloadimgとimg_to_arrayと呼ばれる画像を取り込み、数値配列にするのを簡単に行ってくれるメソッドがあります。今回はそれを用いてリストを作成していきます。\n",
        "また正解データのOnehot化もto_categoricalというメソッドを使うと簡単にOnehot化してくれます。\n",
        "\n",
        "では自作のデータセットを作成してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYuv7CoqhrwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像を読み込む\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def dataset_loader(path , input_shape, classes):\n",
        "    images, labels = [], []\n",
        "    path_list, label_list = [], []\n",
        "    \n",
        "    labeldir = os.listdir(path)\n",
        "    c = 0\n",
        "    for count, labelname in enumerate(labeldir):\n",
        "        label_path = os.path.join(path, labelname)\n",
        "        images_path = os.listdir(label_path)\n",
        "\n",
        "        for imagepath in images_path:\n",
        "            c += 1\n",
        "            path_list.append(os.path.join(label_path, imagepath))\n",
        "            label_list.append(count)\n",
        "        print(\"カテゴリ名 : \", labelname)\n",
        "        print(\"データ数   : \", c)\n",
        "        c = 0\n",
        "    \n",
        "    for image, label in zip(path_list, label_list):\n",
        "        # input image & label.\n",
        "        images.append(img_to_array(load_img(image, target_size=input_shape)) / 255.)\n",
        "        labels.append(to_categorical(label, len(classes)))\n",
        "    inputs = np.asarray(images, np.float32)\n",
        "    targets = np.asarray(labels, np.int8)\n",
        "\n",
        "    return inputs, targets\n",
        "\n",
        "category_list = [\"category1\", \"category2\"]\n",
        "xdata, ydata = dataset_loader(\"./dataset\", (224,224), category_list)\n",
        "print(\"総データ数 : \", len(xdata))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOv5oUEN9JAU",
        "colab_type": "text"
      },
      "source": [
        "自作のデータセットができたと思います。\n",
        "\n",
        "---\n",
        "\n",
        "## データセットの画像を表示してみる。\n",
        "\n",
        "一度、実際に画像を出力してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owuhtCtLttJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5x5枚の画像を表示する\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(25):\n",
        "    rand_num=np.random.randint(0,1000)\n",
        "    cifar_img=plt.subplot(5,5,i+1)\n",
        "    plt.imshow(xdata[rand_num])\n",
        "    #x軸の目盛りを消す\n",
        "    plt.tick_params(labelbottom='off')\n",
        "    #y軸の目盛りを消す\n",
        "    plt.tick_params(labelleft='off')\n",
        "    #正解ラベルを表示\n",
        "    plt.title(ydata[rand_num])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Gj49sXuWfn",
        "colab_type": "text"
      },
      "source": [
        "画像がコマ切れで表示されていると思います。\n",
        "今回はこれを学習していこうと思います。\n",
        "\n",
        "---\n",
        "\n",
        "## モデルを定義してみる\n",
        "\n",
        "学習モデルを定義していきます。今回はVGG16というモデルを使って転移学習というものを試していきたいと思います。転移学習というものは優秀な学習済みモデルの畳み込みフィルタやpoolingなどを利用して、最後の出力層のみを学習するというものでこれを用いることで、素早く高い精度を出すことが可能になっています。\n",
        "\n",
        "またVGG16は画像処理のコンペティション(競技)でいい成績を出せたとてもいいモデルです。このモデルをimagenetと呼ばれる超大量のデータセット群で学習した後のモデルを利用して今回は転移学習を行っていきます。\n",
        "\n",
        "- VGGモデルシリーズの解説 - [Keras：VGG16、VGG19とかってなんだっけ？？ - Qiita](https://qiita.com/MuAuan/items/86a56637a1ebf455e180)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlzskqSreOkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "vgg16=VGG16(weights='imagenet',include_top=False,\n",
        "                 input_shape=(224,224,3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vgg16)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation=\"relu\"))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "#14層目以降を再度学習するように\n",
        "for layer in vgg16.layers[:15]:\n",
        "    layer.trainable=False\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(lr=0.001,momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# モデルアーキテクチャを画像に出力します\n",
        "%matplotlib inline\n",
        "plot_model(model, to_file='_.png', show_shapes=True, show_layer_names=True)\n",
        "im = Image.open('_.png')\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "_ = plt.imshow(np.array(im))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xoKG01UJNYI",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## 学習を行ってみる\n",
        "\n",
        "では実際に学習を行っていきたいと思います。\n",
        "バッチサイズやエポックは今回は少な目で大丈夫です。\n",
        "バッチサイズは学習データが少ないため、エポックは転移学習である程度学習済みのものを使うため少なめでいいということになってます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7esk-kW7p-yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バッチサイズ\n",
        "batch_size = 32\n",
        "\n",
        "# 反復学習する回数\n",
        "epochs = 1\n",
        "\n",
        "# 学習の実行\n",
        "history=model.fit(xdata,ydata,batch_size=batch_size,epochs=epochs,verbose=1,validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQEHrJAzXO-y",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## 学習結果を確認する\n",
        "\n",
        "学習ができたので結果を確認していきましょう\n",
        "まずは損失率や正解率を確認していきます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X72EQZCVXngs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 正答率と損失関数の値の推移をグラフ化します、\n",
        "# 学習時の正答率などの情報は、history変数にすべて記録されています。\n",
        "\n",
        "# 正答率の推移\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.xticks(np.arange(0, 10, 2))\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 損失関数の推移\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.xticks(np.arange(0, 10, 2))\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN4CWKxpXpwW",
        "colab_type": "text"
      },
      "source": [
        "学習できましたか・・・\n",
        "\n",
        "---\n",
        "\n",
        "## 実際に推論してみる\n",
        "\n",
        "推論が正しいのか実際にデータを入れてみて確認してみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQMDdbT0Ya99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO4Wlm5wd-d2",
        "colab_type": "text"
      },
      "source": [
        "モデルを推論してみましょう。\n",
        "Cifar10のおまけと同じような設定です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owc4sNugeIYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagename = \"./test.jpg\"\n",
        "category = [\"0\", \"1\"]\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "#画像読み込み\n",
        "temp_img=load_img(imagename, target_size=(224,224))\n",
        "#画像を配列に変換し0-1で正規化\n",
        "temp_img_array=img_to_array(temp_img)\n",
        "temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "predict_img_array=temp_img_array.reshape((1,224,224,3))\n",
        "\n",
        "img_pred=model.predict_classes(predict_img_array)\n",
        "print('\\npredict_classes=', category[img_pred[0]])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(temp_img_array)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}