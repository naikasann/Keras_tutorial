{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NurealNetwork_tutorial_2_Cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHL+7p9Ojp+AGb3VdinprW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naikasann/Keras_tutorial/blob/master/NurealNetwork_tutorial_2_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkU7izP4kpTA",
        "colab_type": "text"
      },
      "source": [
        "# Kerasを触ってみる(第2章 Cifar10をCNNで解いてみる)\n",
        "\n",
        "次はCifar10と呼ばれるもう少し複雑な画像を判別することができるモデルを作成してみましょう。そのためにCNNと呼ばれる畳み込みニューラルネットワークを利用してみます。\n",
        "\n",
        "ではやっていきましょう\n",
        "\n",
        "---\n",
        "## 全体の流れ\n",
        "\n",
        "全体の流れはこのようになっています。これらを実行しながら、体験的に学んでいきます。\n",
        "\n",
        "```\n",
        "1. Cifar10のデータを見てみよう\n",
        "2. モデルを定義する\n",
        "3. 学習を行う\n",
        "4. 学習結果を確認する\n",
        "5. 実際に推論を行ってみる\n",
        "6. おまけ\n",
        "```\n",
        "### 今回のゴール\n",
        "``` \n",
        "Cifar10の10種類カテゴリを分類して、実際に分類をかけてみることができる\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTiDp56i3X-Y",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "今回の参考記事\n",
        "\n",
        "プログラムは\n",
        "\n",
        "[cifar10とKerasを使ってCNN(Convolutional Neural Network)を実装してみる - Qiita](https://qiita.com/God_KonaBanana/items/10fa8bb58cdd1dbd2e59)\n",
        "\n",
        "を利用させていただき、解説を自分なりのものに変えました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTwhaI0BnM_N",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Kerasのライブラリをインポートする\n",
        "\n",
        "まずはKerasなどののライブラリをインポートしていきます。\n",
        "\n",
        "基本的には同じライブラリを用いて実行していきます。ただ今回はオプティマイザーやロス関数などのKeras内で用いられるライブラリなどを解説していきます。\n",
        "\n",
        "1.   **オプティマイザー**\n",
        "  学習していくうえでの最適化する手法の設定。\n",
        "  RMSPropやAdam,SGDなどが有名です。\n",
        "  前回のMNISTはRMSProp,今回はAdamを選択して学習を行っています。\n",
        "\n",
        "  オプティマイザーはmodel.compileと呼ばれるモデルをコンパイルするメソッドを実行するときの引数として使用します。\n",
        "  色々変えてみて試してみるといいと思います。\n",
        "\n",
        "2.   **ロス関数(損失関数)**\n",
        "  損失関数は学習の答えが近い値になるように重みパラメータを更新するのが目的です。\n",
        "  学習のゴールを決めるような感じです。\n",
        "  mean_squared_error(平均2乗誤差)やcategorical_crossentropy(カテゴリ交差エントロピー)、binary_crossentropy、kullback_leibler_divergenceなどが有名です。\n",
        "\n",
        "  これもmodel.compileの引数として利用します。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC1WQbc8koV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各種使用するライブラリをインポートします。\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPvWZPGvvQXc",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Cifar10のデータを見てみよう。\n",
        "\n",
        "深層学習のためには様々な技術が応用されていることが少しわかってもらえたかなと思います。次に実際のCifar10のデータを見てみたいと思います。Cifar10もKerasのライブラリですぐに導入することができます。\n",
        "\n",
        "次に今回行う問題についてを見ていきましょう。\n",
        "Cifar10は飛行機や犬などの10クラスを分類するような問題になっていています。学習データは5万枚、テストデータは1万枚とかなり大規模で実用的な分類をするような学習問題になっています。まずはどのような画像なのか見ていきましょう。\n",
        "\n",
        "また深層学習に導入できるように整形までをここで行ってしまいます。\n",
        "\n",
        "１０クラスは\n",
        "```\n",
        "1. airplane(飛行機)\n",
        "2. automobile(自動車)\n",
        "3. bird(鳥)\n",
        "4. cat(猫)\n",
        "5. deer(鹿)\n",
        "6. dog(犬)\n",
        "7. frog(カエル)\n",
        "8. horse(馬)\n",
        "9. ship(船)\n",
        "10. truck(トラック)\n",
        "```\n",
        "の10種類を分類します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkKRZCB3wFX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "\n",
        "#5x5枚の画像を表示する\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    rand_num=np.random.randint(0,50000)\n",
        "    cifar_img=plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[rand_num])\n",
        "    #x軸の目盛りを消す\n",
        "    plt.tick_params(labelbottom='off')\n",
        "    #y軸の目盛りを消す\n",
        "    plt.tick_params(labelleft='off')\n",
        "    #正解ラベルを表示\n",
        "    plt.title(y_train[rand_num])\n",
        "plt.show()\n",
        "\n",
        "#画像を0-1の範囲で正規化\n",
        "x_train=x_train.astype('float32')/255.0\n",
        "x_test=x_test.astype('float32')/255.0\n",
        "\n",
        "#正解ラベルをOne-Hot表現に変換\n",
        "y_train=to_categorical(y_train,10)\n",
        "y_test=to_categorical(y_test,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHUgOOm1wvmN",
        "colab_type": "text"
      },
      "source": [
        "このような画像が保存されています。画像が人間にはモザイクのように見えるのは32*32の画像サイズだからです。解像度を上げることでより詳細的に見ることができますが、コンピュータの処理能力の必要性が上がるため、少ない解像度で学習することが多いです。\n",
        "また今回はMNISTと違ってRGBのカラー画像を用いて学習を行っていきます。\n",
        "\n",
        "今回はデータ整形までを一気に行いました。\n",
        "\n",
        "次はモデルの構造を定義していきます。\n",
        "\n",
        "---\n",
        "\n",
        "## モデルを定義する\n",
        "\n",
        "モデルの構造を定義していきます。今回はCNNと呼ばれる畳み込みニューラルネットワークを用いて学習していくことにします。CNNの特徴は画像をあるサイズで区切りその画像で判別していくというものです。CNNは画像において優秀な成績を持っています。また近年では文章も区切って判別するようなCNN(FastText)などもあり、ニューラルネットワークの中でも一番といっていいほど有名なものになりました。\n",
        "\n",
        "CNNはConv層と呼ばれる画像を区切る層と、Pooling層と呼ばれる画像の特徴を際立たせることが目的の層を並べることで実装されることが多いです。では実際にモデルを定義していきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8YEMoPre8GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モデルを構築\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),padding='same',input_shape=(32,32,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32,(3,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64,(3,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# モデルアーキテクチャを画像に出力します\n",
        "%matplotlib inline\n",
        "plot_model(model, to_file='_.png', show_shapes=True, show_layer_names=True)\n",
        "im = Image.open('_.png')\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "_ = plt.imshow(np.array(im))\n",
        "\n",
        "#モデルの表示\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8WMq_hnsLsp",
        "colab_type": "text"
      },
      "source": [
        "モデルは…\n",
        "\n",
        "---\n",
        "\n",
        "## 学習を行う\n",
        "\n",
        "では学習を行ってみます。\n",
        "今回はMNISTより多い回数学習を行いましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia-3xT2iuak3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バッチサイズ\n",
        "batch_size = 512\n",
        "\n",
        "# 反復学習する回数\n",
        "epochs = 20\n",
        "\n",
        "# 学習の実行\n",
        "history=model.fit(x_train,y_train,batch_size=128,epochs=20,verbose=1,validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNNbR9NU6yj6",
        "colab_type": "text"
      },
      "source": [
        "学習にかなり時間が掛かったことが分かったと思います。\n",
        "これは画像を畳み込み処理をしたことによって計算を行う処理の数や複雑性が上がっていることによって起きています。\n",
        "今後も自分の用意した画像なども画像サイズなどによって学習する速度は変わってきます。ただ大きな画像を使うほど、より機械が詳細的にデータをみる機会が与えられることになるためより良い精度のモデルができる可能性が高まります。\n",
        "\n",
        "---\n",
        "\n",
        "## 学習結果を確認する\n",
        "\n",
        "学習ができたら結果を見ていきましょう！まずは損失率や正解率を見ます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COC1cT9du38V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 正答率と損失関数の値の推移をグラフ化します、\n",
        "# 学習時の正答率などの情報は、history変数にすべて記録されています。\n",
        "\n",
        "# 正答率の推移\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.xticks(np.arange(0, 10, 2))\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 損失関数の推移\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.xticks(np.arange(0, 10, 2))\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIgicJfK71QM",
        "colab_type": "text"
      },
      "source": [
        "MNISTに比べて複雑な問題になっているはずですが、しっかりと学習が行えていることが分かってもらえると思います。\n",
        "\n",
        "---\n",
        "\n",
        "## 実際に推論を行ってみる。\n",
        "\n",
        "推論が正しいのか確認します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3JTM6Lb8Ptj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 表示するデータ数(頭から1～25まで対応)\n",
        "display = 10\n",
        "\n",
        "category = (\"airplane\",\n",
        "            \"automobile\",\n",
        "            \"bird\",\n",
        "            \"cat\",\n",
        "            \"deer\",\n",
        "            \"dog\",\n",
        "            \"frog\",\n",
        "            \"horse\",\n",
        "            \"ship\",\n",
        "            \"truck\")\n",
        "\n",
        "print(\"推論結果\")\n",
        "# 検証データに対する予測値の取得\n",
        "y_predict = model.predict(x_test)\n",
        "# 予測値を表示\n",
        "print(y_predict[:display])\n",
        "print(\"正解率\")\n",
        "# 正解データを表示\n",
        "print(y_test[:display])\n",
        "\n",
        "print(\"予測データ(整形後)\")\n",
        "# 予測した結果の中から一番確信度が高いデータを取り出す。(リストのインデックス)\n",
        "predict_list = [np.argmax(prd) for prd in y_predict]\n",
        "buff = predict_list[:display]\n",
        "p_list = []\n",
        "for c in buff:\n",
        "  p_list.append(category[c])\n",
        "print(p_list)\n",
        "print(\"正解データ(整形後)\")\n",
        "# 正解データの生データを表示する。(生データの変数を上でなくしたので復元する)\n",
        "ans_list = [np.argmax(ans) for ans in y_test]\n",
        "buff = ans_list[:display]\n",
        "p_list = []\n",
        "for c in buff:\n",
        "  p_list.append(category[c])\n",
        "print(p_list)\n",
        "\n",
        "# 推論を行ったMNISTデータの表示\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
        "for i in range(display):\n",
        "    ax = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(x_test[i].reshape((32, 32, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN_WVxpX9AxV",
        "colab_type": "text"
      },
      "source": [
        "このような形でCifar10のデータを分類することができました。\n",
        "次はgoogle colabではなく、Pythonのスクリプトで自分が用意した画像データセットを学習してみてカメラで判別するようなものを作成してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbzzoyv-AMD",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## おまけ\n",
        "\n",
        "ネットで拾ってきた画像をCifar10のモデルで推論してみたくないですか？\n",
        "そうすれば自分がその10種類の画像を分類することができるAIを作ることができるという実感がよりわくと思います。(記事の流れまんまですけどね…)\n",
        "実際に推論するようなプログラムを置いておきますので試してみましょう。\n",
        "\n",
        "まずは下のプログラムを実行して画像をアップロードしてください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4TbxZSB9_CA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W2CQnAbHNQu",
        "colab_type": "text"
      },
      "source": [
        "次はその画像をロードしてモデルに推論していただきます。\n",
        "下のプログラムで画像名を変換して実行してみてください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noNYJm61Hl4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagename = \"./OIP.jpg\"\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "#画像読み込み\n",
        "temp_img=load_img(imagename, target_size=(32,32))\n",
        "#画像を配列に変換し0-1で正規化\n",
        "temp_img_array=img_to_array(temp_img)\n",
        "temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "temp_img_array=temp_img_array.reshape((1,32,32,3))\n",
        "\n",
        "img_pred=model.predict_classes(temp_img_array)\n",
        "print('\\npredict_classes=', category[img_pred[0]])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}