{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NueralNetwork_tutorial.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7o6GwGJeyySm8PmDnE2kq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naikasann/Keras_tutorial/blob/master/NueralNetwork_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa4aojFXPMWN",
        "colab_type": "text"
      },
      "source": [
        "# Kerasを触ってみる (第１章 MNIST問題)\n",
        "\n",
        "Kerasは深層学習の有名ライブラリであるTensorflowを比較的簡単に動作するように作成されたラッパーライブラリです。\n",
        "これを使用することで直感的にNN(Nueral Network)を体験することができます。\n",
        "\n",
        "では体験していきましょう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXAw6omd4VMV",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Kerasを実際に触ってみる\n",
        "\n",
        "Kerasを実際に触っていきたいと思います。\n",
        "深層学習を最初に始めるうえで一番初めやすい問題がMNIST問題という問題です。\n",
        "MNISTは0～9までの手書き文字画像をそれぞれどの数字なのか判別するという問題です。\n",
        "まずは実際にMNISTの画像を見てみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VemJJt-SHFqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各種使用するライブラリをインポートします。\n",
        "import tensorflow\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeHesld37ske",
        "colab_type": "text"
      },
      "source": [
        "それぞれのライブラリについて説明していきます。\n",
        "1. **Tensorflow**\n",
        "\n",
        "Googleが開発したオープンソースで公開されている機械学習のライブラリ。PythonやC++などで記述することができる。現在のバージョンは2.2が最新になっている。Google Colabは2.2をデフォルトで設定されている。機械学習で有名なライブラリの一つ。\n",
        "(注意 : バージョン1系と２系で動作が違う部分が多いので気を付ける。Qiitaなどの記事は1系がとても多い。)\n",
        "\n",
        "2. **Keras**\n",
        "\n",
        "Python言語で記述されたニューラルネットワークライブラリ。実際にはTensorflowなど上にいる高水準ライブラリという位置づけ。深層学習を簡単に実行できるようになった立役者。現在おそらく一番運用されている深層学習ツールだと思う。学術的に使うというよりは実装面で素早く作れることにたけているイメージ。\n",
        "バージョンは2.3.1が最新で、Tensorflow２系からはTensorflow内部でのサポートに変わってtf.kerasというものの立ち位置に変わってきている。\n",
        "(製作者はKeras自体のサポートはもう終わると発言。今後はtf.kerasがKerasとして機能。)\n",
        "\n",
        "Keras系のライブラリの説明は大変なので省略。\n",
        "\n",
        "3. **seaborn**\n",
        "\n",
        "グラフ描画のためのライブラリ。有名なライブラリであるMatlabplotに並ぶ有名なライブラリ。\n",
        "\n",
        "4. **Matlabplot**\n",
        "\n",
        "グラフ描画のためのライブラリ。簡単にグラフを描画してくれる。\n",
        "\n",
        "5. **numpy**\n",
        "\n",
        "Python言語のための数値計算を効率的に行うためのライブラリ。計算を行うときにはより詳細的に、素早く計算をしてくれる。\n",
        "多次元計算能力がかなり高くその点が高く評価されている。\n",
        "\n",
        "6. PIL\n",
        "\n",
        "画像を読み取るためにあるPythonの標準ライブラリ。RGB形式で読み取ってくれるためかなり直観的に画像を取り扱うことができる。画像ライブラリではOpencvも有名。どちらを使うかは結構好みがある。\n",
        "\n",
        "---\n",
        "\n",
        "## MNISTのデータを閲覧してみる\n",
        "\n",
        "たくさんのライブラリがあることがわかってもらえたと思います。実際にはもう少し使う場合があります。\n",
        "次に実際のMNISTのデータを見てみたいと思います。\n",
        "MNISTはKerasだと関数を実行するだけですぐにロードすることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnF_SrNU7tKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kerasの関数でデータの読み込み。データをシャッフルして学習データと検証データに分割してくれる\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  \n",
        "#5x5枚の画像を表示する\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    rand_num=np.random.randint(0,50000)\n",
        "    cifar_img=plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[rand_num], cmap=\"gray\")\n",
        "    #x軸の目盛りを消す\n",
        "    plt.tick_params(labelbottom='off')\n",
        "    #y軸の目盛りを消す\n",
        "    plt.tick_params(labelleft='off')\n",
        "    #正解ラベルを表示\n",
        "    plt.title(y_train[rand_num])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXojZ91T897H",
        "colab_type": "text"
      },
      "source": [
        "このような形でロードすることができます。ロードしたデータを一部表示してみました。\n",
        "\n",
        "データのtrain, testというものはtrainが機械学習の勉強用のデータでtestが実際の試験として用いるデータになっています。\n",
        "\n",
        "これは混ぜて学習することは絶対にダメです。人間でいうカンニングになってしまいます。(モデルの整合性チェックでやるときがあるけど基本ダメ。)\n",
        "\n",
        "またx,yというのはxは画像データ、yはそれに対応する答えが格納されています。今回はxをみて学習してもらいyになるような勉強をしていくわけです。なので深層学習の中でも**教師あり学習**というものになります。\n",
        "\n",
        "---\n",
        "\n",
        "## データを整形する\n",
        "\n",
        "表示した画像を見ると人間には簡単に数字として読み取ることができると思いますが、機械だとそうはいきません。なぜかというと数値の並びとしてしか機械は見ることができないからです。また数値というものを画像としてみたこともないから何がどうなのかもわかっていないと思います。\n",
        "\n",
        "ロードした画像データは28*28の数字の並んだものになってます。\n",
        "今回は読み込みやすいように784次元に引き伸ばします。\n",
        "これをすることで機械に簡単に入れやすいようになります。\n",
        "(今後はそうしません。)\n",
        "次に型を画像データはfloat32,教師データはint8に固定します。軽量化や小数点計算などが理由です。\n",
        "\n",
        "また教師データ(答え)は**Onehot形式**に変換していきます。\n",
        "Onehotは一つだけがHIGHで他のデータがLOWになるようなデータであらわされるビット列を指します。\n",
        "今回のデータは\n",
        "\n",
        "```\n",
        "教師データ(答え)\n",
        "9\n",
        "↓\n",
        "Onehot形式の答え\n",
        "state  : [0,1,2,3,4,5,6,7,8,9]\n",
        "onehot : [0,0,0,0,0,0,0,0,0,1]\n",
        "```\n",
        "\n",
        "このような感じで９の状態のみをHIGHにするような形に教師データを加工します。これにすることで次元での計算に対応しやすくなります。\n",
        "\n",
        "これで加工は完成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7UEHqr-dcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習用データの作成\n",
        "# 読み込んだ手書き文字イメージデータを、機械学習の入力にできるよう整形します。\n",
        "# クラス数の定義\n",
        "num_classes = 10\n",
        "# データをそれぞれ784次元に変換\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "# float型に変換する。\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# 画像を正規化する。(計算速度の向上、精度の安定化)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# データ数の確認\n",
        "print( 'Trainデータ数: ', x_train.shape[0])\n",
        "print( 'Testデータ数: ',x_test.shape[0])\n",
        "\n",
        "# 正解データをOnehot表記に変換\n",
        "\n",
        "print('生データ(変更前)')\n",
        "print(y_train[:5])\n",
        "\n",
        "# intの32byte型にする。\n",
        "y_train = y_train.astype('int32')\n",
        "y_test = y_test.astype('int32')\n",
        "# train,testそれぞれのデータをOnehot表記に変換する。\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test =  keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('Onehot表記に変換したもの')\n",
        "print(y_train[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ9WGwz4-jDx",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "次にニューラルネットワークの構造を定義していきます。\n",
        "今回はCNNやRNNなどのようなものではなくかなりシンプルな構造のものを作成します。\n",
        "Kerasはこのモデル定義をSequentialという定義の仕方とFunction APIと呼ばれる定義の仕方があります。Sequentialの方が直観的に定義することができるため今回はそちらを用いて定義します。\n",
        "\n",
        "Sequentialモデルはaddを用いて様々な種類の層を付け足していくことで深層学習を実行できるような仕組みになっています。\n",
        "\n",
        "今回は全結合層を３つ並べた単純なモデルで実験を行いたいと思います。\n",
        "全結合層はKerasではDense,ChainerではLinearと呼ばれています。\n",
        "入力に対して重みのフィルタ(隠れ層)を介して対応した次元数などに出力するような層になっています。\n",
        "この層を利用して784次元を512次元にして一度フィルタを介して１０種類に仕分けるような構造になりました。\n",
        "間のDropoutはフィルタの数をすべて使用するのではなく一部破棄して学習を続けるというものです。\n",
        "\n",
        "実行するとモデルを生成してモデルの構造を文字と画像の２種類で出力されるようになってます。見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LipZJVn8_Ygy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 簡単なモデルなのでSequentialモデルを使います\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# モデルアーキテクチャを画像に出力します\n",
        "%matplotlib inline\n",
        "plot_model(model, to_file='_.png', show_shapes=True, show_layer_names=True)\n",
        "im = Image.open('_.png')\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "_ = plt.imshow(np.array(im))\n",
        "\n",
        "# モデルの出力結果を出します。\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wNLsKV6AgOM",
        "colab_type": "text"
      },
      "source": [
        "学習の設定を定義していきます。エポックやバッチサイズというものを設定していきます。\n",
        "これは学習結果を更新する頻度を設定するものです。バッチサイズは学習データを指定数の個数のグループで分けていきそのグループを学習して学習時点で更新をかけていくものです。大体2の乗数で設定していくのがベターとされています。\n",
        "\n",
        "```\n",
        "例) 100個の学習データを10のバッチサイズに分けて学習\n",
        "　　　　→　１度の学習で　100/10 = 10回　勉強を行う。　\n",
        "```\n",
        "\n",
        "エポックは反復回数といい、学習を何回繰り返すかを指定するものになってます。\n",
        "難しい問題だと回数を増やしていきます。これが深層学習の学習が時間がかかるゆえんになってます。\n",
        "\n",
        "model.fitで学習を開始します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pb62uFcAcQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バッチサイズ\n",
        "batch_size = 128\n",
        "\n",
        "# 反復学習する回数\n",
        "epochs = 10\n",
        "\n",
        "# 学習の実行\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTdsiH6kBtFG",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "これで学習ができました。次に学習結果についてみていきましょう。\n",
        "まずはデータ損失率や正解率を見ていきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HHLPBACvRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 正答率と損失関数の値の推移をグラフ化します、\n",
        "# 学習時の正答率などの情報は、history変数にすべて記録されています。\n",
        "\n",
        "# 正答率の推移\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.xticks(np.arange(0, 10, 2))\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 損失関数の推移\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.xticks(np.arange(0, 10, 2))\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh35Z58OCxqN",
        "colab_type": "text"
      },
      "source": [
        "このようなグラフでデータ損失率や正解率を見ることができました。\n",
        "これを見るとlossというものが下がっていてaccというものが上がっていくことがわかると思います。\n",
        "\n",
        "lossは学習損失率といい、この深層学習で学習ができていない数値を表します。なのでこの数値を0にすることで学習が完了しているということになります。\n",
        "またaccは正答率は教師データと照らし合わせてどれだけ正解しているのかを割合であらわすものになっています。なので100に近づくと完全に理解しているということになります。\n",
        "\n",
        "またValidationというものがあると思います。これは検証データと呼ばれており人間の勉強での過程でいうと小テストの部分に当てはまります。\n",
        "これがlossが低い、accが100に近い方がテストデータもうまく対応することができているという状態になっているといえます。\n",
        "\n",
        "またtrainのデータがかなり高いけどvalidationデータが低い場合があります。これは過学習と呼ばれるトレーニングデータに過剰適合して検証データなどに適合しなくなってしまっている状態のことを言います。なんでこの過学習が起きないようにValidation dataなどを確認しながら学習を行っていきます。\n",
        "\n",
        "---\n",
        "\n",
        "次に実際にどのようにニューラルネットワークがデータを推論(Predict)しているのか確認していきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6WII3HzDgfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 表示するデータ数(頭から1～25まで対応)\n",
        "display = 10\n",
        "\n",
        "print(\"推論結果\")\n",
        "# 検証データに対する予測値の取得\n",
        "y_predict = model.predict(x_test)\n",
        "# 予測値を表示\n",
        "print(y_predict[:display])\n",
        "print(\"正解率\")\n",
        "# 正解データを表示\n",
        "print(y_test[:display])\n",
        "\n",
        "print(\"予測データ(整形後)\")\n",
        "# 予測した結果の中から一番確信度が高いデータを取り出す。(リストのインデックス)\n",
        "predict_list = [np.argmax(prd) for prd in y_predict]\n",
        "print(predict_list[:display])\n",
        "print(\"正解データ(整形後)\")\n",
        "# 正解データの生データを表示する。(生データの変数を上でなくしたので復元する)\n",
        "ans_list = [np.argmax(ans) for ans in y_test]\n",
        "print(ans_list[:display])\n",
        "\n",
        "# 推論を行ったMNISTデータの表示\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
        "for i in range(display):\n",
        "    ax = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(x_test[i].reshape((28, 28)), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h9DZuplENu8",
        "colab_type": "text"
      },
      "source": [
        "このような形で手書き文字を判別することができました。\n",
        "次はより複雑な画像データの推論をしてみましょう。\n",
        "そのためにCNN(Convolution Nueral Network、畳み込みニューラルネットワークとも)を学習していきます。"
      ]
    }
  ]
}